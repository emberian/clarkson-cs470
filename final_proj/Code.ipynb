{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3133,
     "status": "ok",
     "timestamp": 1670274700839,
     "user": {
      "displayName": "Ember Richardson",
      "userId": "05921004582757010193"
     },
     "user_tz": 300
    },
    "id": "ie76vEKeBDAv",
    "outputId": "fc494b1a-0a09-4678-c862-cbda099ec881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import typing\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from numpy.lib import recfunctions as rfn\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display, Math, Latex\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab config\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#os.chdir('/content/drive/My Drive/cs470')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Data Loading\n",
    "\n",
    "The dataset was downloaded from Kaggle. It contains 32 Columns of 1,000,000 entries. Since it is 216.59 MB, it may take time to load.\n",
    "\n",
    "_in this project, \"label\" will refer to column categories, and \"data_actual\" will refer to the actual value of the data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Base.csv\") # load csv from drive\n",
    "classification = data.pop(\"fraud_bool\") # remove classification label from dataset\n",
    "labels = data.keys() # get column labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "## Balance check\n",
    "Our dataset is extremely imbalanced. This is due to the fact that fraudulence overwhelmingly rare in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "In the complete data set, 11029 are fraud (1.103%)"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(f'In the complete data set, {classification.sum()} are fraud ({100*classification.sum()/len(classification):.3f}%)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot vectorization\n",
    "\n",
    "Machine learning algorithms have a hard time understanding strings. To confront this, we replace a column of multiple unique string values with multiple columns for each unique category. These columns contain a boolean to indicate which category it was. This is alternatively known as a _One-hot_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hotify labels\n",
    "labels_categorical = [\"payment_type\", \"employment_status\", \"housing_status\", \"source\", \"device_os\"] # list that contains columns to be binarized\n",
    "labels_vectorized = [] # list that contains all newly created binarized columns\n",
    "for label in labels_categorical:\n",
    "    label_index = data.columns.get_loc(label)\n",
    "    column_binarized = pd.get_dummies(data[label])\n",
    "    for label_binarized in column_binarized:\n",
    "        # new label joins the category with the original column name\n",
    "        label_binarized_new = label + \"_\" + label_binarized\n",
    "        data.insert(\n",
    "            label_index,\n",
    "            label_binarized_new,\n",
    "            column_binarized[label_binarized])\n",
    "        labels_vectorized.append(label_binarized_new)\n",
    "    del data[label]\n",
    "# prove that removal occurred and that new columns were added\n",
    "assert(\"payment_type\" not in data.columns and \"device_os\" not in data.columns and \"device_os_windows\" in data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum-Maximum Normalization\n",
    "\n",
    "The backpropagation algorithm will eventually attempt to normalize the range of values within a column to become from 0 to 1. We can save time by preprocessing the data beforehand, shaving seconds if not minutes off of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum-maximum normalization\n",
    "scaler = MinMaxScaler() # scales data between 0 and 1\n",
    "for label in labels:\n",
    "    if label not in labels_categorical: # check only the ones that were not categorical (this implies columns of numbers, not strings)\n",
    "        data[label] = scaler.fit_transform(data[[label]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning\n",
    "\n",
    "Finally, the data will be partitioned into both training and evaluation subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data partitioning\n",
    "training_ratio = 0.85 # this percent will be used for training\n",
    "training_index = math.floor(len(data)*training_ratio)\n",
    "data_training = (data[:training_index]) # training data\n",
    "labels_training = pd.DataFrame(classification[:training_index]) # training data's actual value\n",
    "data_evaluation = (data[training_index:]) # evaluation data\n",
    "labels_evaluation  = pd.DataFrame(classification[training_index:]) # evaluation data's actual value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Guq81mAAGG_L"
   },
   "source": [
    "# Model Design\n",
    "\n",
    "We will be using a simple Multilayer Neural Network for this project. This is because our data is simply just numbers, which have no spatial significance (like an image), so we will not be using a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "NHTyDJ31HqHb"
   },
   "outputs": [],
   "source": [
    "# model design\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(256, activation=\"relu\", input_shape=(data_training.shape[-1],)),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 256)               13568     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,409\n",
      "Trainable params: 145,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives(), tf.keras.metrics.TrueNegatives(), tf.keras.metrics.TruePositives()])\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 17:14:08.729965: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 353600000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26563/26563 [==============================] - 57s 2ms/step - loss: 0.0516 - binary_accuracy: 0.9887 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - false_positives_10: 28.0000 - false_negatives_10: 9577.0000 - true_negatives_10: 840395.0000 - true_positives_10: 0.0000e+00\n",
      "Epoch 2/3\n",
      "26563/26563 [==============================] - 56s 2ms/step - loss: 0.0501 - binary_accuracy: 0.9887 - precision_10: 0.4045 - recall_10: 0.0038 - false_positives_10: 53.0000 - false_negatives_10: 9541.0000 - true_negatives_10: 840370.0000 - true_positives_10: 36.0000\n",
      "Epoch 3/3\n",
      "26563/26563 [==============================] - 55s 2ms/step - loss: 0.0499 - binary_accuracy: 0.9887 - precision_10: 0.4256 - recall_10: 0.0087 - false_positives_10: 112.0000 - false_negatives_10: 9494.0000 - true_negatives_10: 840311.0000 - true_positives_10: 83.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=data_training,\n",
    "    y=labels_training,\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 947us/step - loss: 0.0451 - binary_accuracy: 0.9903 - precision_10: 1.0000 - recall_10: 6.8871e-04 - false_positives_10: 0.0000e+00 - false_negatives_10: 1451.0000 - true_negatives_10: 148548.0000 - true_positives_10: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.evaluate(data_evaluation, labels_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 16:07:14.649445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 290ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00150064]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([evaluation_dataset[5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
