{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3133,
     "status": "ok",
     "timestamp": 1670274700839,
     "user": {
      "displayName": "Ember Richardson",
      "userId": "05921004582757010193"
     },
     "user_tz": 300
    },
    "id": "ie76vEKeBDAv",
    "outputId": "fc494b1a-0a09-4678-c862-cbda099ec881"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from numpy.lib import recfunctions as rfn\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33891,
     "status": "ok",
     "timestamp": 1670278532791,
     "user": {
      "displayName": "Ember Richardson",
      "userId": "05921004582757010193"
     },
     "user_tz": 300
    },
    "id": "f4fttJacDzEe",
    "outputId": "358931ee-e096-43c0-8512-e3f65aaa1a4d"
   },
   "outputs": [],
   "source": [
    "# data\n",
    "dtypes = {\n",
    "    'fraud_bool': '?',\n",
    "    'income': 'f4',\n",
    "    'name_email_similarity': 'f2',\n",
    "    'prev_address_months_count': 'i2',\n",
    "    'current_address_months_count': 'i2',\n",
    "    'customer_age': 'u1',\n",
    "    'days_since_request': 'f2',\n",
    "    'intended_balcon_amount': 'f2',\n",
    "    'payment_type': 'u1', # STR\n",
    "    'zip_count_4w': 'u2',\n",
    "    'velocity_6h': 'f4',\n",
    "    'velocity_24h': 'f4',\n",
    "    'velocity_4w': 'f4',\n",
    "    'bank_branch_count_8w': 'u2',\n",
    "    'date_of_birth_distinct_emails_4w': 'u1',\n",
    "    'employment_status': 'u2',\n",
    "    'credit_risk_score': 'i2',\n",
    "    'email_is_free': 'u1',\n",
    "    'housing_status': 'u1', # STR\n",
    "    'phone_home_valid': 'u1',\n",
    "    'phone_mobile_valid': 'u1',\n",
    "    'bank_months_count': 'i1',\n",
    "    'has_other_cards': 'u1',\n",
    "    'proposed_credit_limit':\n",
    "    'f2', 'foreign_request': 'u1',\n",
    "    'source': 'u1', # STR\n",
    "    'session_length_in_minutes': 'f4',\n",
    "    'device_os': 'u1', # STR\n",
    "    'keep_alive_session': 'u1',\n",
    "    'device_distinct_emails_8w': 'i1',\n",
    "    'device_fraud_count': 'u1',\n",
    "    'month': 'u1'}\n",
    "\n",
    "def strconv(cat):\n",
    "    seen = {}\n",
    "    def inner(s):\n",
    "        nonlocal seen\n",
    "        if s not in seen:\n",
    "            seen[s] = len(seen)\n",
    "        return seen[s]\n",
    "    return inner\n",
    "\n",
    "strconvs = {\n",
    "    'source': strconv(\"source\"),\n",
    "    'device_os': strconv(\"device_os\"),\n",
    "    'housing_status': strconv(\"housing_status\"),\n",
    "    'payment_type': strconv(\"payment_type\"),\n",
    "    'employment_status': strconv(\"employment_status\")\n",
    "}\n",
    "\n",
    "column_labels = list(next(open('Base.csv')).strip().split(','))\n",
    "converters = {0: lambda s: bool(int(s))}\n",
    "for k, v in strconvs.items():\n",
    "    converters[column_labels.index(k)] = v\n",
    "rawdata = genfromtxt('Base.csv', dtype=[dtypes[n] for n in column_labels],\n",
    "                  names=column_labels, delimiter=',', converters=converters)[1:] # skip header\n",
    "txtdata = list(open('Base.csv').read().split('\\n'))[1:]\n",
    "print(f'Example row: {rawdata[0]} : {type(rawdata[0])}')\n",
    "print(f'Computed type of elements: {rawdata.dtype}')\n",
    "print(f'Same row but unparsed, does it match? {txtdata[0]})')\n",
    "issue = False\n",
    "anyissue = False\n",
    "for rowix, (txtrow, rawrow) in enumerate(zip(txtdata, rawdata)):\n",
    "    if not (rawrow[0] == 0 or rawrow[0] == 1):\n",
    "        print(f'WARN: fraud_bool for row {rowix} is {rawrow[0]}, not 0 or 1!')\n",
    "        anyissue = True\n",
    "\n",
    "    for ix, c in enumerate(rawrow):\n",
    "        if ix == 4 and c == 65535:\n",
    "            continue # this is the one column where -1 as missing is OK\n",
    "        if type(c) != np.str_ and np.isnan(c):\n",
    "            print(f'{rawrow} has a nan at {ix}!')\n",
    "        elif np.issubdtype(type(c), np.integer):\n",
    "            info = np.iinfo(type(c))\n",
    "            if (c == info.min or c == info.max) and c!=0:\n",
    "                issue = True\n",
    "                print(f'WARN: column {ix} row {rowix} ({column_labels[ix]}) has maxed out the irange of {type(c)}!')\n",
    "        elif np.issubdtype(type(c), np.floating):\n",
    "            info = np.finfo(type(c))\n",
    "            if c == info.min or c == info.max:\n",
    "                issue = True\n",
    "                print(f'WARN: column {ix} row {rowix} ({column_labels[ix]}) has maxed out the frange of {type(c)}!')\n",
    "    if issue:\n",
    "        print(f'row was: {rawrow}')\n",
    "        print(f'source data was: {txtrow}')\n",
    "        anyissue = True\n",
    "        issue = False\n",
    "else:\n",
    "    if not anyissue:\n",
    "        print('No issues found with datatype!')\n",
    "    else:\n",
    "        print('Issues found with datatype! Look closely!')\n",
    "data = rfn.structured_to_unstructured(rawdata, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fraud_ground_truth = np.int_(data[:,:1])\n",
    "real_dataset = data[:,1:]  # skip the fraud bool\n",
    "#np.array([np.array(row)[1:] for row in rawdata]) # skip the fraud bool\n",
    "training_size = math.floor(len(real_dataset)*.2)\n",
    "training_dataset = real_dataset[:training_size]\n",
    "evaluation_dataset = real_dataset[training_size:]\n",
    "evaluation_dataset_labels = is_fraud_ground_truth[training_size:]\n",
    "is_fraud_ground_truth_training = is_fraud_ground_truth[:training_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1670278573430,
     "user": {
      "displayName": "Ember Richardson",
      "userId": "05921004582757010193"
     },
     "user_tz": 300
    },
    "id": "PTh3HkUEUfCM",
    "outputId": "f4f08497-159a-49f9-8e07-79608675b5c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.dtype[int64]'>\n",
      "(1000000, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.dtype[int64]'>\n",
      "(200000, 1)\n",
      "[[ 8.9999998e-01  1.5954590e-01 -1.0000000e+00  2.2000000e+01\n",
      "   5.0000000e+01  1.9073486e-02 -1.0000000e+00  2.0000000e+00\n",
      "   8.1000000e+02  3.4570000e+03  4.0540000e+03  3.0220000e+03\n",
      "   1.9210000e+03  6.0000000e+00  1.0000000e+00  1.1000000e+02\n",
      "   1.0000000e+00  1.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   3.1000000e+01  1.0000000e+00  2.0000000e+02  0.0000000e+00\n",
      "   1.0000000e+00  2.0000000e+00  3.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]\n",
      " [ 8.9999998e-01  5.9619141e-01 -1.0000000e+00  2.1800000e+02\n",
      "   5.0000000e+01  4.4403076e-03  0.0000000e+00  2.0000000e+00\n",
      "   8.9000000e+02  5.0200000e+03  2.7280000e+03  3.0870000e+03\n",
      "   1.9900000e+03  2.0000000e+00  1.0000000e+00  2.9500000e+02\n",
      "   1.0000000e+00  1.0000000e+00  1.0000000e+00  0.0000000e+00\n",
      "   3.1000000e+01  0.0000000e+00  1.5000000e+03  0.0000000e+00\n",
      "   1.0000000e+00  3.0000000e+00  4.0000000e+00  1.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]\n",
      " [ 3.0000001e-01  1.4392090e-01 -1.0000000e+00  3.0000000e+01\n",
      "   3.0000000e+01  2.8228760e-02  0.0000000e+00  4.0000000e+00\n",
      "   7.3200000e+02  3.2230000e+03  3.8040000e+03  5.0780000e+03\n",
      "   5.0000000e+00  1.3000000e+01  1.0000000e+00  1.9900000e+02\n",
      "   1.0000000e+00  2.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   1.5000000e+01  0.0000000e+00  2.0000000e+02  0.0000000e+00\n",
      "   1.0000000e+00  4.0000000e+00  1.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]\n",
      " [ 6.9999999e-01  3.2153320e-01 -1.0000000e+00  1.5200000e+02\n",
      "   3.0000000e+01  3.0685425e-02  0.0000000e+00  2.0000000e+00\n",
      "   8.7600000e+02  5.5150000e+03  2.6530000e+03  3.0890000e+03\n",
      "   1.3000000e+01  1.0000000e+01  1.0000000e+00  2.7200000e+02\n",
      "   1.0000000e+00  1.0000000e+00  1.0000000e+00  1.0000000e+00\n",
      "   3.0000000e+01  0.0000000e+00  1.5000000e+03  0.0000000e+00\n",
      "   1.0000000e+00  1.0000000e+00  1.0000000e+00  1.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]\n",
      " [ 8.9999998e-01  6.4819336e-02 -1.0000000e+00  1.8000000e+01\n",
      "   5.0000000e+01  3.4545898e-02 -1.0000000e+00  2.0000000e+00\n",
      "   9.0100000e+02  4.7360000e+03  6.7330000e+03  3.8260000e+03\n",
      "   4.0000000e+01  1.0000000e+00  2.0000000e+00  8.3000000e+01\n",
      "   1.0000000e+00  2.0000000e+00  1.0000000e+00  0.0000000e+00\n",
      "   2.8000000e+01  0.0000000e+00  2.0000000e+02  1.0000000e+00\n",
      "   1.0000000e+00  2.0000000e+00  3.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]\n",
      " [ 6.9999999e-01  6.5917969e-02 -1.0000000e+00  6.4000000e+01\n",
      "   4.0000000e+01  2.0690918e-02 -1.0000000e+00  2.0000000e+00\n",
      "   9.3300000e+02  6.1010000e+03  3.8490000e+03  3.0890000e+03\n",
      "   2.1340000e+03  4.0000000e+00  3.0000000e+00  2.2200000e+02\n",
      "   0.0000000e+00  1.0000000e+00  1.0000000e+00  1.0000000e+00\n",
      "   3.0000000e+01  0.0000000e+00  1.5000000e+03  0.0000000e+00\n",
      "   1.0000000e+00  2.0000000e+00  1.0000000e+00  1.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]\n",
      " [ 8.9999998e-01  7.0019531e-01 -1.0000000e+00  6.0000000e+01\n",
      "   4.0000000e+01  1.6815186e-02 -1.0000000e+00  2.0000000e+00\n",
      "   1.1760000e+03  4.5040000e+03  3.7930000e+03  3.0610000e+03\n",
      "   8.0000000e+00  2.0000000e+00  2.0000000e+00  1.1800000e+02\n",
      "   1.0000000e+00  3.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   2.5000000e+01  0.0000000e+00  2.0000000e+02  0.0000000e+00\n",
      "   1.0000000e+00  2.4000000e+01  1.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.dtype[float32]'>\n",
      "(200000, 31)\n"
     ]
    }
   ],
   "source": [
    "def dbg_ndarray(val):\n",
    "    print(type(val))\n",
    "    print(type(val.dtype))\n",
    "    print(val.shape)\n",
    "dbg_ndarray(is_fraud_ground_truth)\n",
    "dbg_ndarray(is_fraud_ground_truth_training)\n",
    "print(training_dataset[3:10])\n",
    "dbg_ndarray(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1670278116095,
     "user": {
      "displayName": "Ember Richardson",
      "userId": "05921004582757010193"
     },
     "user_tz": 300
    },
    "id": "fPX9g3ZIUen9",
    "outputId": "24fecd2b-2888-4a6e-8806-972ec1e6c3cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.9999998e-01  1.6687012e-01 -1.0000000e+00  8.8000000e+01\n",
      "   5.0000000e+01  2.0919800e-02 -1.0000000e+00  1.0000000e+00\n",
      "   7.6900000e+02  1.0650000e+04  3.1340000e+03  3.8630000e+03\n",
      "   1.0000000e+00  6.0000000e+00  1.0000000e+00  1.8500000e+02\n",
      "   0.0000000e+00  1.0000000e+00  1.0000000e+00  0.0000000e+00\n",
      "   2.4000000e+01  0.0000000e+00  5.0000000e+02  0.0000000e+00\n",
      "   1.0000000e+00  3.0000000e+00  1.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]\n",
      " [ 8.9999998e-01  2.9638672e-01 -1.0000000e+00  1.4400000e+02\n",
      "   5.0000000e+01  5.4168701e-03  0.0000000e+00  2.0000000e+00\n",
      "   3.6600000e+02  5.3400000e+02  2.6700000e+03  3.1240000e+03\n",
      "   7.1800000e+02  3.0000000e+00  1.0000000e+00  2.5900000e+02\n",
      "   1.0000000e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.5000000e+01  0.0000000e+00  1.5000000e+03  0.0000000e+00\n",
      "   1.0000000e+00  3.1000000e+01  1.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  7.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(real_dataset[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Guq81mAAGG_L"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHTyDJ31HqHb"
   },
   "outputs": [],
   "source": [
    "#Model old\n",
    "model: keras.Model = keras.Sequential([\n",
    "    keras.layers.Dense((32**2) * 4, activation='relu'),\n",
    "    keras.layers.Dense((32**2) * 2, activation='relu'),\n",
    "    keras.layers.Dense(32**2, activation='relu'),\n",
    "    keras.layers.Dense((32**2)/4, activation='relu'),\n",
    "    keras.layers.Dense((32**2)/8, activation='relu'),\n",
    "    keras.layers.Dense((32**2)/16, activation='relu'),\n",
    "    keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 00:35:55.871823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5620/5625 [============================>.] - ETA: 0s - loss: 7.6321 - accuracy: 0.0157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 00:36:49.761816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 56s 10ms/step - loss: 7.6321 - accuracy: 0.0157 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "5623/5625 [============================>.] - ETA: 0s - loss: 7.6262 - accuracy: 0.0157"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#fit\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtraining_dataset, y\u001b[39m=\u001b[39;49mis_fraud_ground_truth_training, epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/keras/engine/training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1592\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1593\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1594\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1604\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1605\u001b[0m     )\n\u001b[0;32m-> 1606\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1607\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1608\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1609\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1610\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1611\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1612\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1613\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1614\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1615\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1616\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1617\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1618\u001b[0m )\n\u001b[1;32m   1619\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1620\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1621\u001b[0m }\n\u001b[1;32m   1622\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/keras/engine/training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1944\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   1945\u001b[0m ):\n\u001b[1;32m   1946\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1947\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1949\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/eager/function.py:1805\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1786\u001b[0m \u001b[39m\"\"\"Executes the wrapped function.\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \n\u001b[1;32m   1788\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[39m  ValueError: If `args` contains anything other than Tensors or Variables.\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1804\u001b[0m ctx \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m-> 1805\u001b[0m executing_eagerly \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39;49mexecuting_eagerly()\n\u001b[1;32m   1807\u001b[0m \u001b[39m# Copy saveable status of function's graph to current FuncGraph.\u001b[39;00m\n\u001b[1;32m   1808\u001b[0m default_graph \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#fit\n",
    "history = model.fit(x=training_dataset, y=is_fraud_ground_truth_training, epochs=25, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 78s 3ms/step - loss: 0.6039 - accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "history = model.evaluate(evaluation_dataset, evaluation_dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
